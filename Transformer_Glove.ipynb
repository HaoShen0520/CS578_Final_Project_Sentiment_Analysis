{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TransformerEncoder, TransformerEncoderLayer\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\n\u001B[0;32m      3\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\__init__.py:1146\u001B[0m\n\u001B[0;32m   1143\u001B[0m py_int \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;66;03m# Shared memory manager needs to know the exact location of manager executable\u001B[39;00m\n\u001B[1;32m-> 1146\u001B[0m \u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initExtension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmanager_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m manager_path\n\u001B[0;32m   1149\u001B[0m \u001B[38;5;66;03m# Appease the type checker: it can't deal with direct setting of globals().\u001B[39;00m\n\u001B[0;32m   1150\u001B[0m \u001B[38;5;66;03m# Note that we will see \"too many\" functions when reexporting this way; there\u001B[39;00m\n\u001B[0;32m   1151\u001B[0m \u001B[38;5;66;03m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001B[39;00m\n\u001B[0;32m   1152\u001B[0m \u001B[38;5;66;03m# so that this import is good enough\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\cuda\\__init__.py:22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _get_device_index, _dummy_type\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m classproperty\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraphs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CUDAGraph, graph_pool_handle, graph, \\\n\u001B[0;32m     23\u001B[0m     make_graphed_callables, is_current_stream_capturing\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstreams\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExternalStream, Stream, Event\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m device \u001B[38;5;28;01mas\u001B[39;00m _device\n",
      "File \u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\cuda\\graphs.py:5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _dummy_type\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree_flatten \u001B[38;5;28;01mas\u001B[39;00m _tree_flatten\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree_unflatten \u001B[38;5;28;01mas\u001B[39;00m _tree_unflatten\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_CudaStreamBase\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# Define dummy base classes\u001B[39;00m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:986\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:680\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:846\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:978\u001B[0m, in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:648\u001B[0m, in \u001B[0;36m_compile_bytecode\u001B[1;34m(data, name, bytecode_path, source_path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import string\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-100\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(glove_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_file = 'data/Sentiment.csv'\n",
    "data = pd.read_csv(data_file)\n",
    "data = data[['text', 'sentiment']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+', 'url', text)\n",
    "\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', 'email', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    print(' '.join(tokens))\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sentence_embedding(tokens, embedding_model, embedding_size, length_limit):\n",
    "    token_embeddings = [embedding_model[token] for token in tokens if token in embedding_model]\n",
    "    padding = np.zeros(embedding_size)\n",
    "\n",
    "    if len(token_embeddings) > 0:\n",
    "\n",
    "        if len(token_embeddings) > length_limit:\n",
    "            token_embeddings = token_embeddings[:length_limit]\n",
    "        elif len(token_embeddings) < length_limit:\n",
    "            token_embeddings = token_embeddings + [padding] * (length_limit - len(token_embeddings))\n",
    "\n",
    "        sentence_embedding = np.concatenate(token_embeddings, axis=0)\n",
    "\n",
    "    else:\n",
    "        sentence_embedding = np.zeros(embedding_size * length_limit)\n",
    "\n",
    "    return sentence_embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_glove_embeddings(data, glove_model):\n",
    "    length_limit = 25\n",
    "    embedding_size = glove_model.vector_size\n",
    "    embeddings = np.zeros((len(data), embedding_size * length_limit))\n",
    "\n",
    "    for i, text in enumerate(data['text']):\n",
    "        embeddings[i] = get_sentence_embedding(preprocess_text(text), glove_model, embedding_size, length_limit)\n",
    "\n",
    "    return embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_size = glove_model.vector_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = create_glove_embeddings(train_data, glove_model)\n",
    "X_test = create_glove_embeddings(test_data, glove_model)\n",
    "X_val = create_glove_embeddings(val_data, glove_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_data['sentiment'])\n",
    "y_test = label_encoder.transform(test_data['sentiment'])\n",
    "y_val = label_encoder.transform(val_data['sentiment'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.int64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.5):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size, dropout_rate)\n",
    "        encoder_layers = TransformerEncoderLayer(hidden_size, nhead=8, dim_feedforward=hidden_size*4, dropout=dropout_rate)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * np.sqrt(float(self.hidden_size))\n",
    "        x = self.pos_encoder(x.unsqueeze(1))\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, 0, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "patience = 10\n",
    "stop_counter = 0\n",
    "best_val_loss = np.inf\n",
    "num_layers = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = Transformer(input_size, hidden_size, num_layers, num_classes, dropout_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_f1_scores, val_f1_scores = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct, train_total = 0, 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_dataloader))\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1 = f1_score(y_train_tensor, model(X_train_tensor).argmax(dim=1), average='weighted')\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_dataloader))\n",
    "    val_accuracy = val_correct / val_total * 100\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1 = f1_score(y_val_tensor, model(X_val_tensor).argmax(dim=1), average='weighted')\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}, '\n",
    "          f'Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val F1: {val_f1:.4f}')\n",
    "\n",
    "    # if val_losses[-1] < best_val_loss:\n",
    "    #     best_val_loss = val_losses[-1]\n",
    "    #     stop_counter = 0\n",
    "    #     torch.save(model.state_dict(), 'best_model.pt')\n",
    "    # else:\n",
    "    #     stop_counter += 1\n",
    "    #     if stop_counter >= patience:\n",
    "    #         print(\"Early stopping triggered.\")\n",
    "    #         break\n",
    "\n",
    "# model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct, test_total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = test_correct / test_total * 100\n",
    "test_f1 = f1_score(y_val_tensor, model(X_val_tensor).argmax(dim=1), average='weighted')\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, Test F1: {test_f1:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_f1_scores, label='Train F1-score')\n",
    "plt.plot(val_f1_scores, label='Validation F1-score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
